{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d637308a-1e9f-4a3e-a7c6-55ad964b2487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e7898668-f776-41dc-a91f-9d3a7f770b6c\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"e7898668-f776-41dc-a91f-9d3a7f770b6c\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.0.min.js\", \"https://unpkg.com/@holoviz/panel@1.3.1/dist/panel.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"e7898668-f776-41dc-a91f-9d3a7f770b6c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"e7898668-f776-41dc-a91f-9d3a7f770b6c\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.0.min.js\", \"https://unpkg.com/@holoviz/panel@1.3.1/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e7898668-f776-41dc-a91f-9d3a7f770b6c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "import warnings\n",
    "import itertools\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import iqplot\n",
    "import bebi103\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "import bokeh.layouts\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f824a1-ac55-432a-b370-7cee6beaed09",
   "metadata": {},
   "source": [
    "### Specifying the data, models, main effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8309f421-b015-46c2-9492-8546f935d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'MotorBehaviordata_NAC_Livia022924.xlsx'\n",
    "data_path = os.path.join(\"..\", \"..\", \"Data\", \"NAC\", filename)\n",
    "sheet_name = 'Pole and Beam'\n",
    "\n",
    "# Group factors\n",
    "effect_1 = 'Genotype' \n",
    "effect_2 = 'Treatment' # \"Treatment\" or \"Microbiome\"\n",
    "\n",
    "# Type pf test for current analysis\n",
    "mtest = 'Pole_T' # \"Beam_T\" or \"Pole_T\"\n",
    "\n",
    "# List of models to fit into and assess\n",
    "# Encoded models: 'weibull', 'weibull_mixed', 'lognormal', 'lognormal_mixed', 'normal', 'normal_mixed', \n",
    "# 'inverse_gamma', 'inverse_gamma_mixed', 'gamma', 'gamma_mixed'\n",
    "models = ['weibull', 'weibull_mixed', 'lognormal', 'lognormal_mixed', 'normal', 'normal_mixed', \n",
    "          'inverse_gamma', 'inverse_gamma_mixed', 'gamma', 'gamma_mixed']\n",
    "\n",
    "# Whether or not the experiment has several cohorts and a dedicated cohort column\n",
    "cohort_col = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a4f77-aa82-425a-846b-5975fa0ed510",
   "metadata": {},
   "source": [
    "### Plotting characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c9e558-b7d5-42ea-97ad-172d22e9bbd7",
   "metadata": {},
   "source": [
    "Specifying palettes and plotting order depending on the data used (SPF/GF, NAC, Auronafin, DJKO experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8016113-7aeb-4ecc-8ba0-a228a0c89dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palettes:\n",
    "palette_CI = [\"#bdbdbd\", \"#000000\", \"#bdbdbd\", \"#000000\"]\n",
    "\n",
    "# Plotting orders:\n",
    "order = {'WT_V': 1, 'ASO_V': 2, 'WT_NAC': 3, 'ASO_NAC': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fb440-0d11-4f7c-bb01-cc1d221c38f8",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b08a3b-0ed3-4b69-a2b0-75b92667e6b1",
   "metadata": {},
   "source": [
    "Tidying up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94155883-b717-47bd-958f-001d7c8f126c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../../Data/NAC/MotorBehaviordata_NAC_Livia022924.xlsx/MotorBehaviordata_NAC_Livia022924.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pole_beam_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, filename), sheet_name\u001b[38;5;241m=\u001b[39msheet_name)\n\u001b[1;32m      2\u001b[0m pole_beam_df \u001b[38;5;241m=\u001b[39m pole_beam_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID \u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup \u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTreatment\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (effect_1 \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pole_beam_df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;129;01mor\u001b[39;00m (effect_2 \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pole_beam_df\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[0;32m~/miniconda3/envs/bebi103/lib/python3.11/site-packages/pandas/io/excel/_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[1;32m    505\u001b[0m         io,\n\u001b[1;32m    506\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    507\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    508\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    509\u001b[0m     )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/bebi103/lib/python3.11/site-packages/pandas/io/excel/_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1564\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1565\u001b[0m     )\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1570\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/bebi103/lib/python3.11/site-packages/pandas/io/excel/_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1420\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bebi103/lib/python3.11/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../../Data/NAC/MotorBehaviordata_NAC_Livia022924.xlsx/MotorBehaviordata_NAC_Livia022924.xlsx'"
     ]
    }
   ],
   "source": [
    "pole_beam_df = pd.read_excel(data_path, sheet_name=sheet_name)\n",
    "pole_beam_df = pole_beam_df.rename(columns={'ID ':'ID', 'Group ':'Group', 'treatment':'Treatment'})\n",
    "\n",
    "if (effect_1 not in pole_beam_df.columns) or (effect_2 not in pole_beam_df.columns):\n",
    "    pole_beam_df[[effect_1, effect_2]] = pole_beam_df['Group'].str.split('-', expand = True)\n",
    "\n",
    "pole_beam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ade60-be84-4aba-ad9e-dbad5e784c36",
   "metadata": {},
   "source": [
    "Creating the working data frame only with the values of interest, removing missing values and cases where mice jumped off of the pole/beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de188a05-8a4b-4ed9-a84c-d05fcab1bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_beam_df = pole_beam_df.replace(to_replace = 'jumped', value = float(\"NaN\"))\n",
    "\n",
    "res = [i for i in list(pole_beam_df.columns) if (mtest) in i]\n",
    "\n",
    "if cohort_col:\n",
    "    col_list = [cohort_col, effect_1, effect_2, 'ID']\n",
    "else:\n",
    "    col_list = [effect_1, effect_2, 'ID']\n",
    "\n",
    "pole_df = pole_beam_df[col_list + res].copy()\n",
    "pole_df_long = pole_df.melt(id_vars = col_list, var_name='Trial', value_name='Time')\n",
    "pole_df_long['Trial'] = pole_df_long['Trial'].str[-2:]\n",
    "pole_df_long['ID'] = pole_df_long['ID'].astype('str')\n",
    "pole_df_long = pole_df_long.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab87867-451b-4f27-9d74-a027fc6e9bce",
   "metadata": {},
   "source": [
    "Creating dictionaries with groups as keys and experimentally measured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41473bb8-56da-4f0a-851b-85658c92ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_vals = {}\n",
    "\n",
    "effect1_lst = pole_df_long[effect_1].unique()\n",
    "effect2_lst = pole_df_long[effect_2].unique()\n",
    "\n",
    "for i in effect1_lst:\n",
    "    for j in effect2_lst:\n",
    "        name = i + '_' + j\n",
    "        n = pole_df_long.loc[(pole_df_long[effect_1] == i) & (pole_df_long[effect_2] == j), 'Time'].values\n",
    "        if len(n) != 0:\n",
    "            group_vals[name] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276937c6-b802-4601-89d4-a77944a6fcba",
   "metadata": {},
   "source": [
    "### Defining all the necessary functions for the MLE calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2018169-631d-47f3-a783-a71cc50da19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_weibull_mixed(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. weibull measurements mixed with Dirac delta function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters alpha, sigma, omega.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    alpha, sigma, omega = params\n",
    "\n",
    "    if alpha <= 0 or sigma <= 0 or omega <=0 or omega >= 1:\n",
    "        return -np.inf\n",
    "\n",
    "    target = 0\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += scipy.special.logsumexp([np.log(1 - omega), np.log(omega) + np.log(1 - st.weibull_min.cdf(i, alpha, scale=sigma))])\n",
    "        else:\n",
    "            target += np.log(omega) + st.weibull_min.logpdf(i, alpha, scale=sigma)\n",
    "                                              \n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e5b43-864f-4170-b7b8-48eb8f0971e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_weibull(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. weibull measurements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters alpha, sigma, omega.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    alpha, sigma = params\n",
    "\n",
    "    if alpha <= 0 or sigma <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "    target = 0\n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += np.log(1 - st.weibull_min.cdf(i, alpha, scale=sigma))\n",
    "        else:\n",
    "            target += st.weibull_min.logpdf(i, alpha, scale=sigma)\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6997e0-ddab-4bcb-807e-4aa05a9eb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_lognormal_mixed(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. lognormal measurements mixed with Dirac delta function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma, omega.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    mu, sigma, omega = params\n",
    "\n",
    "    if mu <= 0 or sigma <= 0 or omega <=0 or omega >= 1:\n",
    "        return -np.inf\n",
    "\n",
    "    target = 0\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += scipy.special.logsumexp([np.log(1 - omega), np.log(omega) + np.log(1 - st.lognorm.cdf(i, sigma, scale=np.exp(mu)))])\n",
    "        else:\n",
    "            target += np.log(omega) + st.lognorm.logpdf(i, sigma, scale=np.exp(mu))\n",
    "                                              \n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be338e-0a8a-4072-9560-21ae60c62768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_lognormal(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. lognormal measurements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    mu, sigma = params\n",
    "\n",
    "    if mu <= 0 or sigma <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.lognorm.cdf(60, sigma, scale=np.exp(mu)))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += cdf_val\n",
    "        else:\n",
    "            target += st.lognorm.logpdf(i, sigma, scale=np.exp(mu))\n",
    "\n",
    "    return target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5cd069-423e-4c83-bad7-1bd708231758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_normal_mixed(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. normal measurements mixed with Dirac delta function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma, omega.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    mu, sigma, omega = params\n",
    "\n",
    "    if mu <= 0 or sigma <= 0 or omega <=0 or omega >= 1:\n",
    "        return -np.inf\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.norm.cdf(60, mu, sigma))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += scipy.special.logsumexp([np.log(1 - omega), np.log(omega) + cdf_val])\n",
    "        else:\n",
    "            target += np.log(omega) + st.norm.logpdf(i, mu, sigma)\n",
    "                                              \n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0430368-3539-44d7-be7f-ff3872eb151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_normal(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. normal measurements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    mu, sigma = params\n",
    "\n",
    "    if mu <= 0 or sigma <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.norm.cdf(60, mu, sigma))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += cdf_val\n",
    "        else:\n",
    "            target += st.norm.logpdf(i, mu, sigma)\n",
    "\n",
    "    return target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeed97-7eaa-452d-836b-01befd77b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_gamma_mixed(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. gamma measurements mixed with Dirac delta function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma, omega.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    alpha, beta, omega = params\n",
    "\n",
    "    if alpha <= 0 or beta <= 0 or omega <=0 or omega >= 1:\n",
    "        return -np.inf\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.gamma.cdf(60, alpha, loc=0, scale=1/beta))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += scipy.special.logsumexp([np.log(1 - omega), np.log(omega) + cdf_val])\n",
    "        else:\n",
    "            target += np.log(omega) + st.gamma.logpdf(i, alpha, loc=0, scale=1/beta)\n",
    "                                              \n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0d495-d2b9-4573-b6a9-7c2532b5f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_gamma(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. gamma measurements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    alpha, beta = params\n",
    "\n",
    "    if alpha <= 0 or beta <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.gamma.cdf(60, alpha, loc=0, scale=1/beta))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += cdf_val\n",
    "        else:\n",
    "            target += st.gamma.logpdf(i, alpha, loc=0, scale=1/beta)\n",
    "\n",
    "    return target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d5745-27ff-4e2b-846e-6074dd42fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_inv_gamma_mixed(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. inverse gamma measurements mixed with Dirac delta function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma, omega.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    alpha, beta, omega = params\n",
    "\n",
    "    if alpha <= 0 or beta <= 0 or omega <=0 or omega >= 1:\n",
    "        return -np.inf\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.invgamma.cdf(60, alpha, loc=0, scale=beta))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += scipy.special.logsumexp([np.log(1 - omega), np.log(omega) + cdf_val])\n",
    "        else:\n",
    "            target += np.log(omega) + st.invgamma.logpdf(i, alpha, loc=0, scale=beta)\n",
    "                                              \n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb38505-1f23-4568-85b3-23c96cde66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_iid_inv_gamma(params, n):\n",
    "    \"\"\"Log likelihood for i.i.d. inverse gamma measurements.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "    alpha, beta = params\n",
    "\n",
    "    if alpha <= 0 or beta <= 0:\n",
    "        return -np.inf\n",
    "\n",
    "\n",
    "    target = 0\n",
    "\n",
    "    cdf_val = np.log(1 - st.invgamma.cdf(60, alpha, loc=0, scale=beta))\n",
    "    \n",
    "    for i in n:\n",
    "        if i == 60:\n",
    "            target += cdf_val\n",
    "        else:\n",
    "            target += st.invgamma.logpdf(i, alpha, loc=0, scale=beta)\n",
    "\n",
    "    return target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708fefe-a55e-4856-8fce-f7528b2c28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_iid_lognormal_mixed(n):\n",
    "    \n",
    "    \"\"\"Performs maximum likelihood estimates for parameters for i.i.d.\n",
    "    lognormal mixed measurements, parametrized by mu, sigma\"\"\"\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        res = scipy.optimize.minimize(\n",
    "            fun=lambda params, n: -log_like_iid_lognormal_mixed(params, n),\n",
    "            x0=np.array([2, 5, 0.5]),\n",
    "            args=(n,),\n",
    "            method='Powell'\n",
    "        )\n",
    "\n",
    "    if res.success:\n",
    "        return res.x\n",
    "    else:\n",
    "        raise RuntimeError('Convergence failed with message', res.message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c7e74-96c2-4e1d-8c1b-d67c93ff7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lognormal_mixed(params, size, rng):\n",
    "    \"\"\"Draws a sample out of the mixed lognormal distribution with Dirac delta function\n",
    "    parametrized by mu, sigma and omega.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma, omega.\n",
    "    size : int\n",
    "        Number of data poinst in a sample.\n",
    "    rng: Generator\n",
    "        The initialized generator object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : array\n",
    "        Newly generated sample.\n",
    "    \n",
    "    \"\"\"\n",
    "    mu, sigma, omega = params\n",
    "\n",
    "    num_max = rng.binomial(size, (1 - omega))\n",
    "    y_max = np.ones(num_max) * 60\n",
    "    num_weib = size - num_max\n",
    "\n",
    "    y_lognorm = st.lognorm.rvs(sigma, scale=np.exp(mu), size=num_weib)\n",
    "\n",
    "    if len(y_max) == 0:\n",
    "        y = y_lognorm\n",
    "    else:\n",
    "        y = np.concatenate((y_lognorm, y_max))\n",
    "\n",
    "    y[y > 60] = 60\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca96eef-f10e-434b-8de7-d0d8644aa214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(params, n, model):\n",
    "    \"\"\"\n",
    "    Log likelihood for i.i.d. measurements for the given model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "        Parameters mu, sigma.\n",
    "    n : array\n",
    "        Array of data points.\n",
    "    model : string\n",
    "        One of the following: 'weibull', 'weibull_mixed', 'lognormal', 'lognormal_mixed', 'normal', 'normal_mixed', \n",
    "            'gamma', 'gamma_mixed', 'inverse gamma', 'inverse_gamma_mixed'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        Log-likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    if model == 'weibull':\n",
    "        return log_like_iid_weibull(params, n)\n",
    "    elif model == 'weibull_mixed':\n",
    "        return log_like_iid_weibull_mixed(params, n)\n",
    "    elif model == 'lognormal':\n",
    "        return log_like_iid_lognormal(params, n)\n",
    "    elif model == 'lognormal_mixed':\n",
    "        return log_like_iid_lognormal_mixed(params, n)\n",
    "    elif model == 'normal':\n",
    "        return log_like_iid_normal(params, n)\n",
    "    elif model == 'normal_mixed':\n",
    "        return log_like_iid_normal_mixed(params, n)\n",
    "    elif model == 'gamma':\n",
    "        return log_like_iid_gamma(params, n)\n",
    "    elif model == 'gamma_mixed':\n",
    "        return log_like_iid_gamma_mixed(params, n)\n",
    "    elif model == 'inverse_gamma':\n",
    "        return log_like_iid_inv_gamma(params, n)\n",
    "    elif model == 'inverse_gamma_mixed':\n",
    "        return log_like_iid_inv_gamma_mixed(params, n)\n",
    "    else:\n",
    "        raise ValueError('Pick an appropriate model!')\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22e42d-28dd-4185-90ac-7eedbc0a8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_iid(n, model):\n",
    "    \"\"\"Performs maximum likelihood estimates for parameters for i.i.d.\n",
    "    measurements of a chosen model;\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : array\n",
    "        Array of data points.\n",
    "    model : string\n",
    "        One of the following: 'weibull', 'weibull_mixed', 'lognormal', 'lognormal_mixed', 'normal', 'normal_mixed', \n",
    "            'gamma', 'gamma_mixed', 'inverse gamma', 'inverse_gamma_mixed'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : float\n",
    "        MLE for given model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    if model == 'weibull':\n",
    "        init_guess = np.array([2, 15])\n",
    "    elif model == 'weibull_mixed':\n",
    "        init_guess = np.array([2, 15, 0.1])\n",
    "    elif model == 'lognormal':\n",
    "        init_guess = np.array([2, 15])\n",
    "    elif model == 'lognormal_mixed':\n",
    "        init_guess = np.array([2, 15, 0.5])\n",
    "    elif model == 'normal':\n",
    "        init_guess = np.array([10, 15])\n",
    "    elif model == 'normal_mixed':\n",
    "        init_guess = np.array([10, 15, 0.5])\n",
    "    elif model == 'gamma':\n",
    "        init_guess = np.array([0.1, 10])\n",
    "    elif model == 'gamma_mixed':\n",
    "        init_guess = np.array([0.5, 10, 0.5])\n",
    "    elif model == 'inverse_gamma':\n",
    "        init_guess = np.array([5, 15])\n",
    "    elif model == 'inverse_gamma_mixed':\n",
    "        init_guess = np.array([5, 15, 0.5])\n",
    "    else:\n",
    "        raise ValueError('Pick an appropriate model!')\n",
    "\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        res = scipy.optimize.minimize(\n",
    "            fun=lambda params, n: -log_like(params, n, model),\n",
    "            x0=init_guess,\n",
    "            args=(n,),\n",
    "            method='Powell'\n",
    "        )\n",
    "\n",
    "        if res.success:\n",
    "            return res.x\n",
    "        else:\n",
    "            raise RuntimeError('Convergence failed with message', res.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f98b7-40a1-46a2-a4ef-292dc2a45d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_perm_sample(x, y):\n",
    "    \"\"\"Generate a permutation sample.\"\"\"\n",
    "    concat_data = np.concatenate((x, y))\n",
    "    np.random.shuffle(concat_data)\n",
    "\n",
    "    return concat_data[:len(x)], concat_data[len(x):]\n",
    "\n",
    "\n",
    "def draw_perm_reps(x, y, stat_fun, size=1):\n",
    "    \"\"\"Generate array of permuation replicates.\"\"\"\n",
    "    return np.array([stat_fun(*draw_perm_sample(x, y)) for _ in range(size)])\n",
    "\n",
    "def draw_perm_reps_diff_mean(x, y, size=1):\n",
    "    \"\"\"Generate array of permuation replicates.\"\"\"\n",
    "    out = np.empty(size)\n",
    "    for i in range(size):\n",
    "        x_perm, y_perm = draw_perm_sample(x, y)\n",
    "        out[i] = np.abs(np.mean(x_perm) - np.mean(y_perm))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86854a0-9154-4aa3-a3ad-7fa2365d2724",
   "metadata": {},
   "source": [
    "Plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a225b0f-ed3f-4122-b5c9-71f903affdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_int_pub(data, parameter_name, palette):\n",
    "    \"\"\"Creating a plot of confidence intervals of a given parameter for given data using the specified palette.\n",
    "    The output is a plot with high resolution that can be exported as an .svg or .html file.\"\"\"\n",
    "    p = bebi103.viz.confints(\n",
    "        data,\n",
    "        title=parameter_name+' 95%CI, lognormal mixed model',\n",
    "        palette=palette,\n",
    "        frame_width=4000,\n",
    "        frame_height=800,\n",
    "        hidpi=True,\n",
    "        line_width=5,\n",
    "        marker_kwargs={\"size\":15}\n",
    "    )\n",
    "    \n",
    "    p.title.text_font_size = '48pt'\n",
    "    p.xaxis.major_label_text_font_size = \"40pt\"\n",
    "    p.yaxis.major_label_text_font_size = \"40pt\"\n",
    "    p.output_backend = 'svg'\n",
    "    \n",
    "    return p\n",
    "\n",
    "def plot_conf_int_notebook(data, parameter_name, palette):\n",
    "    \"\"\"Creating a plot of confidence intervals of a given parameter for given data using the specified palette.\n",
    "    The output is a plot that can be viewed in the notebook.\"\"\"\n",
    "    \n",
    "    p = bebi103.viz.confints(\n",
    "        data,\n",
    "        title=parameter_name+' 95%CI, lognormal mixed model',\n",
    "        palette=palette\n",
    "    )\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941d3bf-ef58-4045-8241-19b169d6c5b0",
   "metadata": {},
   "source": [
    "### Calculating MLEs and AICs for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20125ef2-dca1-4653-a999-60c9a28ac9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mles_dict = {}\n",
    "models = ['weibull', 'weibull_mixed', 'lognormal', 'lognormal_mixed', 'normal', 'normal_mixed']\n",
    "\n",
    "AICs = pd.DataFrame(index = models)\n",
    "\n",
    "for model in models:\n",
    "    mles_dict[model] = {}\n",
    "    for group in group_vals.keys():\n",
    "        if len(group_vals[group]) != 0:\n",
    "            params = mle_iid(group_vals[group], model=model)\n",
    "        \n",
    "            mles_dict[model][group] = params\n",
    "    \n",
    "            _llk = log_like(params, group_vals[group], model = model)\n",
    "            AICs.loc[model, group] = -2 * (_llk - len(params))\n",
    "\n",
    "AICs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294d2cf-df94-45ab-a440-9dbff70fe1c4",
   "metadata": {},
   "source": [
    "## Mixed Lognormal model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6277a6-483d-49a5-99a5-192a0cdb4446",
   "metadata": {},
   "source": [
    "Fitting data into the mixed lognormal model with Dirac delta function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db70f8-0b4f-40c7-b9f5-01129cf2b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_mles = mles_dict['lognormal_mixed']\n",
    "ln_mles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700792fe-a0d3-450b-921a-8af2c6c6b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_mle_samples_mx_ln = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d0429-0a2f-402e-97ec-260aab2ec784",
   "metadata": {},
   "source": [
    "Drawing bootstrap replicates of parameter MLEs for every group in the experiment.  \n",
    "**Choose an appropriate amount for <code>n_jobs</code> according to the number of cores available on the machine. Windows users might need to set it to 1 to make it work. There is another option of using previously generated bootstrap samples - refer to the code below the following coding cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3a2d2-3b37-4650-8c62-7a30ef8bd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in group_vals.keys():\n",
    "    print(group)\n",
    "\n",
    "    bs_mle_sample = bebi103.bootstrap.draw_bs_reps_mle(\n",
    "        mle_iid,\n",
    "        gen_lognormal_mixed,\n",
    "        data=group_vals[group],\n",
    "        mle_args=('lognormal_mixed',),\n",
    "        size=10000,\n",
    "        n_jobs=3\n",
    "    )\n",
    "    \n",
    "    _df = pd.DataFrame(bs_mle_sample, columns=['mu', 'sigma', 'omega'])\n",
    "    _df.to_csv(os.path.join(\"..\", \"Output\", group+\"nac_pole_bs_mle_samples.csv\"))\n",
    "\n",
    "    bs_mle_samples_mx_ln[group] = bs_mle_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369617ff-445d-434c-9c19-095edb904ca4",
   "metadata": {},
   "source": [
    "**If you are unable to run the code cell above or it takes too long, you can use the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cff799-96b1-4078-8141-096ce0a110a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in group_vals.keys():\n",
    "    _df = pd.read_csv(os.path.join(\"..\", \"Output\", group+\"nac_pole_bs_mle_samples.csv\"), index_col=0)\n",
    "    bs_mle_samples_mx_ln[group] = _df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd5389-9842-46d5-b81d-c808d000c244",
   "metadata": {},
   "source": [
    "## Plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5ddbe-748c-4f1b-b468-40d85ac4faa8",
   "metadata": {},
   "source": [
    "### Graphical model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d0b13-537e-41bd-8bea-9eee340738a7",
   "metadata": {},
   "source": [
    "Generating bootstrap samples for further graphical model assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfa009-c16e-40ad-9e89-756b4018af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_samples_mx_ln = {}\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "for group in sorted(group_vals, key=lambda x: order[x]):\n",
    "    params = ln_mles[group]\n",
    "    single_samples = np.array([gen_lognormal_mixed(params, size=len(group_vals[group]), rng=rng) for _ in range(100000)])\n",
    "    bs_samples_mx_ln[group] = single_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736af53-32bb-40c9-864a-aaed241f82bd",
   "metadata": {},
   "source": [
    "Making Q-Q plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1aca3-67db-4335-9614-a7d72094dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplots_mx_ln =[]\n",
    "precdf_plots_mx_ln = []\n",
    "\n",
    "for group in sorted(group_vals, key=lambda x: order[x]):\n",
    "\n",
    "    p = bebi103.viz.qqplot(\n",
    "        data=group_vals[group],\n",
    "        samples=bs_samples_mx_ln[group],\n",
    "        x_axis_label=\"time of descent\",\n",
    "        y_axis_label=\"time of descent\",\n",
    "        title=group + ' Q-Q plot'       \n",
    "    )\n",
    "    qqplots_mx_ln.append(p)\n",
    "\n",
    "    p1 = bebi103.viz.predictive_ecdf(\n",
    "        samples=bs_samples_mx_ln[group], \n",
    "        data=group_vals[group], \n",
    "        x_axis_label=\"time\",\n",
    "        title=group + ' predictive ECDF'\n",
    "    )\n",
    "    precdf_plots_mx_ln.append(p1)\n",
    "\n",
    "qq_lt_mx_ln = bokeh.layouts.row(qqplots_mx_ln)\n",
    "\n",
    "bokeh.io.show(qq_lt_mx_ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3dabe-b79b-4816-93e4-f2bf18f9ffc7",
   "metadata": {},
   "source": [
    "Making predictive ECDF plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1e013-28db-4c2b-acf8-0d770348bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_lt_mx_ln = bokeh.layouts.row(precdf_plots_mx_ln)\n",
    "\n",
    "bokeh.io.show(pe_lt_mx_ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187e1a9-f011-4d56-a848-aee85abd8adb",
   "metadata": {},
   "source": [
    "### Generating 95% confidence intervals for the parameter MLEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf33fc-aff7-4f9a-99a8-6ef856fdcc02",
   "metadata": {},
   "source": [
    "Creating specific dictionary structure needed for the parameter 95% confidence interval plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b3e24-a7eb-4921-b1a4-05aafe3c4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_lst_mx_ln = []\n",
    "sigma_lst_mx_ln = []\n",
    "omega_lst_mx_ln = []\n",
    "\n",
    "mus_mx_ln = {}\n",
    "sigmas_mx_ln = {}\n",
    "omegas_mx_ln = {}\n",
    "\n",
    "for group in sorted(group_vals, key=lambda x: order[x]):\n",
    "    _smpls = bs_mle_samples_mx_ln[group]\n",
    "    _mu_CI = np.percentile(_smpls[:, 0], [2.5, 97.5])\n",
    "    _sigma_CI = np.percentile(_smpls[:, 1], [2.5, 97.5])\n",
    "    _omega_CI = np.percentile(_smpls[:, 2], [2.5, 97.5])\n",
    "\n",
    "    mu_mle, sigma_mle, omega_mle = ln_mles[group]\n",
    "\n",
    "    _mu_dct = { 'label':group, 'conf_int':_mu_CI, 'estimate':mu_mle}\n",
    "    _sigma_dct = { 'label':group, 'conf_int':_sigma_CI, 'estimate':sigma_mle}\n",
    "    _omega_dct = { 'label':group, 'conf_int':_omega_CI, 'estimate':omega_mle}\n",
    "\n",
    "    mu_lst_mx_ln.append(_mu_dct)\n",
    "    sigma_lst_mx_ln.append(_sigma_dct)\n",
    "    omega_lst_mx_ln.append(_omega_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9be0f3-8f89-4d37-b749-bad0c3116dd3",
   "metadata": {},
   "source": [
    "Plotting and saving 95% confidence interval plot for the mu parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d699c-4400-4720-bf40-95b7a9f65986",
   "metadata": {},
   "source": [
    "## Null hypothesis significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ee36e-5126-4da2-afe7-cca5ebb4e8f4",
   "metadata": {},
   "source": [
    "Kruskall-Wallis analysis of the groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a29b3-ea04-4776-93b5-87971a2faf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_ks = st.kruskal(group_vals['WT_V'], group_vals['ASO_V'], group_vals['WT_NAC'], group_vals['ASO_NAC'])\n",
    "p_val_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ceb36-7a61-4b7d-9b2c-934fb119955d",
   "metadata": {},
   "source": [
    "Post-hoc Conover pairwise comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fef84b-86fd-4443-8614-f4e591625d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = sp.posthoc_conover([group_vals['WT_V'], group_vals['ASO_V'], group_vals['WT_NAC'], group_vals['ASO_NAC']], \n",
    "                            p_adjust='fdr_bh')\n",
    "p_vals = p_vals.rename(columns={1:'WT_V', 2:'ASO_V', 3:'WT_NAC', 4:'ASO_NAC'}, \n",
    "                       index={1:'WT_V', 2:'ASO_V', 3:'WT_NAC', 4:'ASO_NAC'})\n",
    "p_vals['KruskalWallis p-val'] = p_val_ks.pvalue\n",
    "p_vals['KruskalWallis statistic'] = p_val_ks.statistic\n",
    "p_vals.to_csv(os.path.join(\"..\", \"Output\", \"nac_pole_KW_conover.csv\"))\n",
    "p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98928a7-de5c-4c3f-b18d-ef7471efe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,numba,bokeh,bebi103,jupyterlab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
